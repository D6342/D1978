import pandas as pd 
import numpy as np 
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, Flatten, Input, Dense,
Concatenate, Dropout
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import LabelEncoder

# 1. Load the MovieLens dataset
url = "https://files.grouplens.org/datasets/movielens/ml-latest- small.zip"
data_path = tf.keras.utils.get_file("ml-latest-small.zip", url, extract=True)
ratings_file = data_path.replace("ml-latest-small.zip", "ml-latest- small/ratings.csv")
ratings = pd.read_csv(ratings_file)

# 2. Preprocess the data
# Encode userId and movieId as integers 
user_encoder = LabelEncoder() 
item_encoder = LabelEncoder()

ratings['userId'] = user_encoder.fit_transform(ratings['userId']) 
ratings['movieId'] = item_encoder.fit_transform(ratings['movieId'])

num_users = ratings['userId'].nunique() 
num_movies = ratings['movieId'].nunique()

# Prepare train and test datasets
X = ratings[['userId', 'movieId']].values 
y = ratings['rating'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Define the collaborative filtering model
def build_model(num_users, num_movies, embedding_dim=50): 
    # User embedding
    user_input = Input(shape=(1,), name="user_input") 
    user_embedding = Embedding(input_dim=num_users,
output_dim=embedding_dim, name="user_embedding")(user_input) 
    user_vector = Flatten()(user_embedding)

# Movie embedding
    movie_input = Input(shape=(1,), name="movie_input") 
    movie_embedding = Embedding(input_dim=num_movies,
output_dim=embedding_dim, name="movie_embedding")(movie_input)   
    movie_vector = Flatten()(movie_embedding)
 

# Concatenate user and movie embeddings
    concat = Concatenate()([user_vector, movie_vector])   
    dense = Dense(128, activation='relu')(concat) 
    dense = Dropout(0.3)(dense)
    dense = Dense(64, activation='relu')(dense) 
    dense = Dropout(0.3)(dense)
    output = Dense(1)(dense) # Predict rating

    model = Model(inputs=[user_input, movie_input], outputs=output) return model

# Build the model 
embedding_dim = 50
model = build_model(num_users, num_movies, embedding_dim) 
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# 4. Train the model 
history = model.fit(
    [X_train[:, 0], X_train[:, 1]], y_train,
    validation_data=([X_test[:, 0], X_test[:, 1]], y_test), 
    epochs=10,
    batch_size=64
)

# 5. Evaluate the model
loss, mae = model.evaluate([X_test[:, 0], X_test[:, 1]], y_test) 
print(f"Test MAE: {mae:.4f}")

# 6. Make predictions
user_id = 15 # Example: A valid user ID from the dataset 
movie_id = 17 # Example: A valid movie ID from the dataset

# Make a prediction
predicted_rating = model.predict([np.array([user_id]), 
np.array([movie_id])])
print(f"Predicted rating for user {user_id} and movie {movie_id}:
{predicted_rating[0][0]:.2f}")
